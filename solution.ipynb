{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Status of existing checking account</th>\n",
       "      <th>Duration in month</th>\n",
       "      <th>Credit history</th>\n",
       "      <th>Purpose</th>\n",
       "      <th>Credit amount</th>\n",
       "      <th>Savings account/bonds</th>\n",
       "      <th>Present employment since</th>\n",
       "      <th>Installment rate in percentage of disposable income</th>\n",
       "      <th>Personal status and sex</th>\n",
       "      <th>Other debtors/guarantors</th>\n",
       "      <th>...</th>\n",
       "      <th>Porperty</th>\n",
       "      <th>Age in years</th>\n",
       "      <th>Other installment plans</th>\n",
       "      <th>Housing</th>\n",
       "      <th>Number of existing credits at this bank</th>\n",
       "      <th>Job</th>\n",
       "      <th>Number of people being liable to provide maintenance for</th>\n",
       "      <th>Telephone</th>\n",
       "      <th>Foreign worker</th>\n",
       "      <th>Creditworthy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A14</td>\n",
       "      <td>36</td>\n",
       "      <td>A32</td>\n",
       "      <td>?</td>\n",
       "      <td>2299</td>\n",
       "      <td>A63</td>\n",
       "      <td>?</td>\n",
       "      <td>4</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>...</td>\n",
       "      <td>A123</td>\n",
       "      <td>39</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>1</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "      <td>A191</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A12</td>\n",
       "      <td>18</td>\n",
       "      <td>A32</td>\n",
       "      <td>A46</td>\n",
       "      <td>1239</td>\n",
       "      <td>A65</td>\n",
       "      <td>A73</td>\n",
       "      <td>4</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>...</td>\n",
       "      <td>A124</td>\n",
       "      <td>61</td>\n",
       "      <td>A143</td>\n",
       "      <td>A153</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A13</td>\n",
       "      <td>24</td>\n",
       "      <td>A32</td>\n",
       "      <td>A40</td>\n",
       "      <td>947</td>\n",
       "      <td>A61</td>\n",
       "      <td>A74</td>\n",
       "      <td>4</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>...</td>\n",
       "      <td>A124</td>\n",
       "      <td>38</td>\n",
       "      <td>A141</td>\n",
       "      <td>A153</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>2</td>\n",
       "      <td>A191</td>\n",
       "      <td>?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A14</td>\n",
       "      <td>15</td>\n",
       "      <td>A33</td>\n",
       "      <td>A43</td>\n",
       "      <td>1478</td>\n",
       "      <td>A61</td>\n",
       "      <td>A73</td>\n",
       "      <td>4</td>\n",
       "      <td>A94</td>\n",
       "      <td>A101</td>\n",
       "      <td>...</td>\n",
       "      <td>A121</td>\n",
       "      <td>33</td>\n",
       "      <td>A141</td>\n",
       "      <td>A152</td>\n",
       "      <td>2</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A14</td>\n",
       "      <td>24</td>\n",
       "      <td>A32</td>\n",
       "      <td>A40</td>\n",
       "      <td>1525</td>\n",
       "      <td>A64</td>\n",
       "      <td>A74</td>\n",
       "      <td>4</td>\n",
       "      <td>A92</td>\n",
       "      <td>A101</td>\n",
       "      <td>...</td>\n",
       "      <td>A123</td>\n",
       "      <td>34</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>1</td>\n",
       "      <td>A173</td>\n",
       "      <td>2</td>\n",
       "      <td>A192</td>\n",
       "      <td>A201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Status of existing checking account  Duration in month Credit history  \\\n",
       "0                                 A14                 36            A32   \n",
       "1                                 A12                 18            A32   \n",
       "2                                 A13                 24            A32   \n",
       "3                                 A14                 15            A33   \n",
       "4                                 A14                 24            A32   \n",
       "\n",
       "  Purpose  Credit amount Savings account/bonds Present employment since  \\\n",
       "0       ?           2299                   A63                        ?   \n",
       "1     A46           1239                   A65                      A73   \n",
       "2     A40            947                   A61                      A74   \n",
       "3     A43           1478                   A61                      A73   \n",
       "4     A40           1525                   A64                      A74   \n",
       "\n",
       "   Installment rate in percentage of disposable income  \\\n",
       "0                                                  4     \n",
       "1                                                  4     \n",
       "2                                                  4     \n",
       "3                                                  4     \n",
       "4                                                  4     \n",
       "\n",
       "  Personal status and sex Other debtors/guarantors  ...  Porperty  \\\n",
       "0                     A93                     A101  ...      A123   \n",
       "1                     A93                     A101  ...      A124   \n",
       "2                     A93                     A101  ...      A124   \n",
       "3                     A94                     A101  ...      A121   \n",
       "4                     A92                     A101  ...      A123   \n",
       "\n",
       "  Age in years  Other installment plans Housing  \\\n",
       "0           39                     A143    A152   \n",
       "1           61                     A143    A153   \n",
       "2           38                     A141    A153   \n",
       "3           33                     A141    A152   \n",
       "4           34                     A143    A152   \n",
       "\n",
       "  Number of existing credits at this bank   Job  \\\n",
       "0                                       1  A173   \n",
       "1                                       1     ?   \n",
       "2                                       1     ?   \n",
       "3                                       2  A173   \n",
       "4                                       1  A173   \n",
       "\n",
       "  Number of people being liable to provide maintenance for  Telephone  \\\n",
       "0                                                  1             A191   \n",
       "1                                                  1             A191   \n",
       "2                                                  2             A191   \n",
       "3                                                  1             A191   \n",
       "4                                                  2             A192   \n",
       "\n",
       "  Foreign worker Creditworthy  \n",
       "0              ?            1  \n",
       "1           A201            1  \n",
       "2              ?            2  \n",
       "3           A201            1  \n",
       "4           A201            1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read flash.dat to a list of lists\n",
    "datContent = [i.strip().split() for i in open(\"./kredit.dat\").readlines()]\n",
    "\n",
    "#write it as a new CSV file\n",
    "with open(\"./kredit.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(datContent)\n",
    "\n",
    "#naming the labels of the columns\n",
    "columns = ['Status of existing checking account','Duration in month','Credit history','Purpose','Credit amount','Savings account/bonds','Present employment since','Installment rate in percentage of disposable income',\n",
    "'Personal status and sex','Other debtors/guarantors','Present residence since','Porperty','Age in years','Other installment plans','Housing','Number of existing credits at this bank','Job','Number of people being liable to provide maintenance for',\n",
    "'Telephone','Foreign worker','Creditworthy']\n",
    "\n",
    "#creating the dataframe\n",
    "df = pd.read_csv('./kredit.csv',names=columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status of existing checking account                         object\n",
      "Duration in month                                            int64\n",
      "Credit history                                              object\n",
      "Purpose                                                     object\n",
      "Credit amount                                                int64\n",
      "Savings account/bonds                                       object\n",
      "Present employment since                                    object\n",
      "Installment rate in percentage of disposable income          int64\n",
      "Personal status and sex                                     object\n",
      "Other debtors/guarantors                                    object\n",
      "Present residence since                                      int64\n",
      "Porperty                                                    object\n",
      "Age in years                                                 int64\n",
      "Other installment plans                                     object\n",
      "Housing                                                     object\n",
      "Number of existing credits at this bank                      int64\n",
      "Job                                                         object\n",
      "Number of people being liable to provide maintenance for     int64\n",
      "Telephone                                                   object\n",
      "Foreign worker                                              object\n",
      "Creditworthy                                                 int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes) #display the data type of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Duration in month</th>\n",
       "      <th>Credit amount</th>\n",
       "      <th>Installment rate in percentage of disposable income</th>\n",
       "      <th>Present residence since</th>\n",
       "      <th>Age in years</th>\n",
       "      <th>Number of existing credits at this bank</th>\n",
       "      <th>Number of people being liable to provide maintenance for</th>\n",
       "      <th>Telephone</th>\n",
       "      <th>Creditworthy</th>\n",
       "      <th>A11</th>\n",
       "      <th>...</th>\n",
       "      <th>A152</th>\n",
       "      <th>A153</th>\n",
       "      <th>A171</th>\n",
       "      <th>A172</th>\n",
       "      <th>A173</th>\n",
       "      <th>A174</th>\n",
       "      <th>Job ?</th>\n",
       "      <th>A201</th>\n",
       "      <th>A202</th>\n",
       "      <th>Foreign worker ?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36.0</td>\n",
       "      <td>2299.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.0</td>\n",
       "      <td>1239.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.0</td>\n",
       "      <td>947.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1478.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.0</td>\n",
       "      <td>1525.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Duration in month  Credit amount  \\\n",
       "0               36.0         2299.0   \n",
       "1               18.0         1239.0   \n",
       "2               24.0          947.0   \n",
       "3               15.0         1478.0   \n",
       "4               24.0         1525.0   \n",
       "\n",
       "   Installment rate in percentage of disposable income  \\\n",
       "0                                                4.0     \n",
       "1                                                4.0     \n",
       "2                                                4.0     \n",
       "3                                                4.0     \n",
       "4                                                4.0     \n",
       "\n",
       "   Present residence since  Age in years  \\\n",
       "0                      4.0          39.0   \n",
       "1                      4.0          61.0   \n",
       "2                      3.0          38.0   \n",
       "3                      3.0          33.0   \n",
       "4                      3.0          34.0   \n",
       "\n",
       "   Number of existing credits at this bank  \\\n",
       "0                                      1.0   \n",
       "1                                      1.0   \n",
       "2                                      1.0   \n",
       "3                                      2.0   \n",
       "4                                      1.0   \n",
       "\n",
       "   Number of people being liable to provide maintenance for  Telephone  \\\n",
       "0                                                1.0               0.0   \n",
       "1                                                1.0               0.0   \n",
       "2                                                2.0               0.0   \n",
       "3                                                1.0               0.0   \n",
       "4                                                2.0               1.0   \n",
       "\n",
       "   Creditworthy  A11  ...  A152  A153  A171  A172  A173  A174  Job ?  A201  \\\n",
       "0           1.0  0.0  ...   1.0   0.0   0.0   0.0   1.0   0.0    0.0   0.0   \n",
       "1           1.0  0.0  ...   0.0   1.0   0.0   0.0   0.0   0.0    1.0   1.0   \n",
       "2          -1.0  0.0  ...   0.0   1.0   0.0   0.0   0.0   0.0    1.0   0.0   \n",
       "3           1.0  0.0  ...   1.0   0.0   0.0   0.0   1.0   0.0    0.0   1.0   \n",
       "4           1.0  0.0  ...   1.0   0.0   0.0   0.0   1.0   0.0    0.0   1.0   \n",
       "\n",
       "   A202  Foreign worker ?  \n",
       "0   0.0               1.0  \n",
       "1   0.0               0.0  \n",
       "2   0.0               1.0  \n",
       "3   0.0               0.0  \n",
       "4   0.0               0.0  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "style = OneHotEncoder()\n",
    "\n",
    "df.loc[df['Purpose'] == '?', 'Purpose'] = 'Purpose ?'\n",
    "df.loc[df['Present employment since'] == '?', 'Present employment since'] = 'Present employment since ?'\n",
    "df.loc[df['Job'] == '?', 'Job'] = 'Job ?'\n",
    "df.loc[df['Foreign worker'] == '?', 'Foreign worker'] = 'Foreign worker ?'\n",
    "\n",
    "non_numerics = df.select_dtypes(include='object')\n",
    "non_numerics = non_numerics.drop('Telephone',axis=1) #only has two classes, which means we can transform it within the column to 0 for A191 and 1 for A192\n",
    "df.loc[df['Telephone'] == 'A191', 'Telephone'] = 0.0\n",
    "df.loc[df['Telephone'] == 'A192', 'Telephone'] = 1.0\n",
    "df['Telephone'] = df['Telephone'].astype('int64')\n",
    "for i in non_numerics.columns.tolist():\n",
    "    transformation = style.fit_transform(df[[i]]) #transform column i\n",
    "    df = df.join(pd.DataFrame(transformation.toarray(), columns=style.categories_[0])) #add new categories (of transformation) to our dataframe\n",
    "    for col in style.categories_[0]:\n",
    "        df[col] = df[col].astype('int64')\n",
    "    df = df.drop(i, axis=1) #dropping old column since we transformed its information\n",
    "\n",
    "df.loc[df['Creditworthy'] == 1, 'Creditworthy'] = 1.0\n",
    "df.loc[df['Creditworthy'] == 2, 'Creditworthy'] = -1.0\n",
    "\n",
    "df = df.astype('float64')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score_normalize(X, indices):\n",
    "    for i in indices:\n",
    "        column = np.array([v[i] for v in X])\n",
    "        mean = np.mean(column)\n",
    "        std = np.std(column)\n",
    "        for j, v in enumerate(column):\n",
    "            X[j][i] = (v - mean) / std\n",
    "    for j in range(0, len(X)):\n",
    "        X[j] = np.array(X[j])\n",
    "    return X\n",
    "\n",
    "numerical_non_missing = [\n",
    "    'Duration in month', \n",
    "    'Credit amount', \n",
    "    'Age in years', \n",
    "    'Installment rate in percentage of disposable income', \n",
    "    'Present residence since', \n",
    "    'Number of existing credits at this bank', \n",
    "    'Number of people being liable to provide maintenance for'\n",
    "]\n",
    "\n",
    "for v in numerical_non_missing:\n",
    "    df[v] = df[v].astype('float64')\n",
    "\n",
    "indices = [df.columns.get_loc(v) for v in numerical_non_missing]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\mathcal{l}(x^T \\theta, y) = \\begin{cases} |x^T \\theta - y| \\cdot 5, & \\text{if $x^T \\theta - y>0$}.\\\\ |x^T \\theta - y|, & \\text{otherwise}.\\end{cases}$$\n",
    "\n",
    "$$\\Omega_2(\\theta) = \\theta^T\\theta$$\n",
    "\n",
    "$$\\frac{\\partial}{\\partial \\theta_i} \\Omega_2(\\theta) = 2 \\cdot \\theta_i$$\n",
    "\n",
    "$$L(\\theta) = \\sum^n_{i = 1} \\left[\\mathcal{l}(x_i^T \\theta, y_i) + \\frac{\\lambda}{n} \\Omega_2(\\theta)\\right]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_pred, y_true):\n",
    "    if y_pred == y_true:\n",
    "        return 0\n",
    "    if y_pred == 1:\n",
    "        return 5\n",
    "    return 1\n",
    "\n",
    "def imperical_risk(y_pred, y_true):\n",
    "    loss = 0\n",
    "    for i in range(0, len(y_pred)):\n",
    "        loss += loss_function(y_pred[i], y_true[i])\n",
    "    return loss / len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.587\n",
      "{'C': 100, 'gamma': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "def svm_classifier():\n",
    "    splits = 5\n",
    "    kf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=0)\n",
    "\n",
    "    X = df[[i for i in df.columns.tolist() if i != 'Creditworthy']].values\n",
    "    y = df['Creditworthy'].values\n",
    "\n",
    "    params = {\n",
    "        'C': [0.1, 1, 10, 100, 1000],\n",
    "        'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "    }\n",
    "\n",
    "    test_split = [v for v in kf.split(X, y)]\n",
    "\n",
    "    params_star = {\n",
    "        'C': 0.1,\n",
    "        'gamma': 1\n",
    "    }\n",
    "\n",
    "    risk = 0\n",
    "    min_risk_Si = np.inf\n",
    "\n",
    "    for i, (rest_index, test_index) in enumerate(test_split):\n",
    "        X_test = X[test_index]\n",
    "        X_test = z_score_normalize(X_test, indices)\n",
    "        y_test = y[test_index]\n",
    "\n",
    "        X_rest = X[rest_index]\n",
    "        y_rest = y[rest_index]\n",
    "\n",
    "        tune_split = [v for v in kf.split(X_rest, y_rest)]\n",
    "        min_risk_without_Si = np.inf\n",
    "        params_star_i = {\n",
    "            'C': 0.1,\n",
    "            'gamma': 1\n",
    "        }\n",
    "\n",
    "        for C in params['C']:\n",
    "            for gamma in params['gamma']:\n",
    "\n",
    "                risk_without_Si = 0\n",
    "\n",
    "                for j, (train_index, tune_index) in enumerate(tune_split):\n",
    "                    X_train = X[train_index]\n",
    "                    X_train = z_score_normalize(X_train, indices)\n",
    "                    y_train = y[train_index]\n",
    "\n",
    "                    X_tune = X[tune_index]\n",
    "                    X_tune = z_score_normalize(X_tune, indices)\n",
    "                    y_tune = y[tune_index]\n",
    "\n",
    "                    model_ij = svm.SVC(C=C, gamma=gamma, kernel='rbf', random_state=0, class_weight='balanced',)\n",
    "                    model_ij.fit(X_train, y_train)\n",
    "\n",
    "                    y_pred = model_ij.predict(X_tune)\n",
    "                    risk_Sj = imperical_risk(y_pred, y_tune)\n",
    "                    risk_without_Si += risk_Sj\n",
    "\n",
    "                risk_without_Si = risk_without_Si / splits\n",
    "\n",
    "                if min_risk_without_Si > risk_without_Si:\n",
    "                    params_star_i = {\n",
    "                        'C': C,\n",
    "                        'gamma': gamma\n",
    "                    }\n",
    "                    min_risk_without_Si = risk_without_Si\n",
    "            \n",
    "        X_rest = z_score_normalize(X_rest, indices)\n",
    "\n",
    "        model_i = svm.SVC(C=params_star_i['C'], gamma=params_star_i['gamma'], kernel='rbf', random_state=0, class_weight='balanced',)\n",
    "        model_i.fit(X_rest, y_rest)\n",
    "        y_pred = model_i.predict(X_test)\n",
    "\n",
    "        risk_Si = imperical_risk(y_pred, y_test)\n",
    "        #print(f\"Recall: {recall_score(y_test, y_pred)}\")\n",
    "        #print(f\"Precision: {precision_score(y_test, y_pred)}\")\n",
    "        risk += risk_Si\n",
    "        if min_risk_Si > risk_Si:\n",
    "            min_risk_Si = risk_Si\n",
    "            params_star = params_star_i\n",
    "\n",
    "    risk = risk / len(test_split)\n",
    "\n",
    "    X = z_score_normalize(X, indices)\n",
    "    model = svm.SVC(C=params_star['C'], gamma=params_star['gamma'], kernel='rbf', random_state=0, class_weight='balanced',)\n",
    "    print(risk)\n",
    "    print(params_star)\n",
    "\n",
    "svm_classifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5820000000000001\n",
      "{'max_depth': 3, 'min_samples_split': 0.1, 'min_samples_leaf': 0.3}\n"
     ]
    }
   ],
   "source": [
    "def decision_tree_classifier():\n",
    "    splits = 5\n",
    "    kf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=0)\n",
    "\n",
    "    X = df[[i for i in df.columns.tolist() if i != 'Creditworthy']].values\n",
    "    y = df['Creditworthy'].values\n",
    "\n",
    "    params = {\n",
    "        'max_depth': [3, 5, 6, 7, 8, 9, 10, 12, 15, 20, 30, None],\n",
    "        'min_samples_split': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.9],\n",
    "        'min_samples_leaf': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.9]\n",
    "    }\n",
    "\n",
    "    test_split = [v for v in kf.split(X, y)]\n",
    "\n",
    "    params_star = {\n",
    "        'max_depth': 3,\n",
    "        'min_samples_split': 0.1,\n",
    "        'min_samples_leaf': 0.1\n",
    "    }\n",
    "\n",
    "    risk = 0\n",
    "    min_risk_Si = np.inf\n",
    "\n",
    "    for i, (rest_index, test_index) in enumerate(test_split):\n",
    "        X_test = X[test_index]\n",
    "        X_test = z_score_normalize(X_test, indices)\n",
    "        y_test = y[test_index]\n",
    "\n",
    "        X_rest = X[rest_index]\n",
    "        y_rest = y[rest_index]\n",
    "\n",
    "        tune_split = [v for v in kf.split(X_rest, y_rest)]\n",
    "        min_risk_without_Si = np.inf\n",
    "        params_star_i = {\n",
    "            'max_depth': 3,\n",
    "            'min_samples_split': 0.1,\n",
    "            'min_samples_leaf': 0.1\n",
    "        }\n",
    "\n",
    "        for max_depth in params['max_depth']:\n",
    "            for min_samples_split in params['min_samples_split']:\n",
    "                for min_samples_leaf in params['min_samples_leaf']:\n",
    "\n",
    "                    risk_without_Si = 0\n",
    "\n",
    "                    for j, (train_index, tune_index) in enumerate(tune_split):\n",
    "                        X_train = X[train_index]\n",
    "                        X_train = z_score_normalize(X_train, indices)\n",
    "                        y_train = y[train_index]\n",
    "\n",
    "                        X_tune = X[tune_index]\n",
    "                        X_tune = z_score_normalize(X_tune, indices)\n",
    "                        y_tune = y[tune_index]\n",
    "\n",
    "                        model_ij = tree.DecisionTreeClassifier(\n",
    "                            max_depth=max_depth, \n",
    "                            min_samples_split=min_samples_split, \n",
    "                            min_samples_leaf=min_samples_leaf,\n",
    "                            criterion='entropy',\n",
    "                            class_weight='balanced',\n",
    "                            random_state=0\n",
    "                        )\n",
    "                        model_ij.fit(X_train, y_train)\n",
    "\n",
    "                        y_pred = model_ij.predict(X_tune)\n",
    "                        risk_Sj = imperical_risk(y_pred, y_tune)\n",
    "                        risk_without_Si += risk_Sj\n",
    "\n",
    "                    risk_without_Si = risk_without_Si / splits\n",
    "\n",
    "                    if min_risk_without_Si > risk_without_Si:\n",
    "                        params_star_i = {\n",
    "                            'max_depth': max_depth,\n",
    "                            'min_samples_split': min_samples_split,\n",
    "                            'min_samples_leaf': min_samples_leaf\n",
    "                        }\n",
    "                        min_risk_without_Si = risk_without_Si\n",
    "            \n",
    "        X_rest = z_score_normalize(X_rest, indices)\n",
    "\n",
    "        model_i = tree.DecisionTreeClassifier(\n",
    "            max_depth=params_star_i['max_depth'], \n",
    "            min_samples_split=params_star_i['min_samples_split'], \n",
    "            min_samples_leaf=params_star_i['min_samples_leaf'],\n",
    "            criterion='entropy',\n",
    "            class_weight='balanced',\n",
    "            random_state=0\n",
    "        )\n",
    "        model_i.fit(X_rest, y_rest)\n",
    "        y_pred = model_i.predict(X_test)\n",
    "\n",
    "        risk_Si = imperical_risk(y_pred, y_test)\n",
    "        #print(f\"Recall: {recall_score(y_test, y_pred)}\")\n",
    "        #print(f\"Precision: {precision_score(y_test, y_pred)}\")\n",
    "        risk += risk_Si\n",
    "        if min_risk_Si > risk_Si:\n",
    "            min_risk_Si = risk_Si\n",
    "            params_star = params_star_i\n",
    "\n",
    "    risk = risk / len(test_split)\n",
    "\n",
    "    X = z_score_normalize(X, indices)\n",
    "    model = tree.DecisionTreeClassifier(\n",
    "        max_depth=params_star['max_depth'], \n",
    "        min_samples_split=params_star['min_samples_split'], \n",
    "        min_samples_leaf=params_star['min_samples_leaf'],\n",
    "        criterion='entropy',\n",
    "        class_weight='balanced',\n",
    "        random_state=0\n",
    "    )\n",
    "    print(risk)\n",
    "    print(params_star)\n",
    "\n",
    "decision_tree_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_classifier():\n",
    "    splits = 5\n",
    "    kf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=0)\n",
    "\n",
    "    X = df[[i for i in df.columns.tolist() if i != 'Creditworthy']].values\n",
    "    y = df['Creditworthy'].values\n",
    "\n",
    "    params = {\n",
    "        'n_estimators': [5, 7, 10, 15, 30, 50, 75, 100],\n",
    "        'max_depth': [3, 5, 6, 7, 8, 9, 10, 12, 15, 20, 30, None],\n",
    "        'min_samples_split': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.9],\n",
    "        'min_samples_leaf': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.9]\n",
    "    }\n",
    "\n",
    "    test_split = [v for v in kf.split(X, y)]\n",
    "\n",
    "    params_star = {\n",
    "        'n_estimators': 5,\n",
    "        'max_depth': 3,\n",
    "        'min_samples_split': 0.1,\n",
    "        'min_samples_leaf': 0.1\n",
    "    }\n",
    "\n",
    "    risk = 0\n",
    "    min_risk_Si = np.inf\n",
    "\n",
    "    for i, (rest_index, test_index) in enumerate(test_split):\n",
    "        X_test = X[test_index]\n",
    "        X_test = z_score_normalize(X_test, indices)\n",
    "        y_test = y[test_index]\n",
    "\n",
    "        X_rest = X[rest_index]\n",
    "        y_rest = y[rest_index]\n",
    "\n",
    "        tune_split = [v for v in kf.split(X_rest, y_rest)]\n",
    "        min_risk_without_Si = np.inf\n",
    "        params_star_i = {\n",
    "            'n_estimators': 5,\n",
    "            'max_depth': 3,\n",
    "            'min_samples_split': 0.1,\n",
    "            'min_samples_leaf': 0.1\n",
    "        }\n",
    "\n",
    "        for n_estimators in params['n_estimators']:\n",
    "            for max_depth in params['max_depth']:\n",
    "                for min_samples_split in params['min_samples_split']:\n",
    "                    for min_samples_leaf in params['min_samples_leaf']:\n",
    "\n",
    "                        risk_without_Si = 0\n",
    "\n",
    "                        for j, (train_index, tune_index) in enumerate(tune_split):\n",
    "                            X_train = X[train_index]\n",
    "                            X_train = z_score_normalize(X_train, indices)\n",
    "                            y_train = y[train_index]\n",
    "\n",
    "                            X_tune = X[tune_index]\n",
    "                            X_tune = z_score_normalize(X_tune, indices)\n",
    "                            y_tune = y[tune_index]\n",
    "\n",
    "                            model_ij = RandomForestClassifier(\n",
    "                                n_estimators=n_estimators,\n",
    "                                max_depth=max_depth, \n",
    "                                min_samples_split=min_samples_split, \n",
    "                                min_samples_leaf=min_samples_leaf,\n",
    "                                criterion='entropy',\n",
    "                                class_weight='balanced',\n",
    "                                random_state=0\n",
    "                            )\n",
    "                            model_ij.fit(X_train, y_train)\n",
    "\n",
    "                            y_pred = model_ij.predict(X_tune)\n",
    "                            risk_Sj = imperical_risk(y_pred, y_tune)\n",
    "                            risk_without_Si += risk_Sj\n",
    "\n",
    "                        risk_without_Si = risk_without_Si / splits\n",
    "\n",
    "                        if min_risk_without_Si > risk_without_Si:\n",
    "                            params_star_i = {\n",
    "                                'n_estimators': n_estimators,\n",
    "                                'max_depth': max_depth,\n",
    "                                'min_samples_split': min_samples_split,\n",
    "                                'min_samples_leaf': min_samples_leaf\n",
    "                            }\n",
    "                            min_risk_without_Si = risk_without_Si\n",
    "            \n",
    "        X_rest = z_score_normalize(X_rest, indices)\n",
    "\n",
    "        model_i = RandomForestClassifier(\n",
    "            n_estimators=params_star_i['n_estimators'],\n",
    "            max_depth=params_star_i['max_depth'], \n",
    "            min_samples_split=params_star_i['min_samples_split'], \n",
    "            min_samples_leaf=params_star_i['min_samples_leaf'],\n",
    "            criterion='entropy',\n",
    "            class_weight='balanced',\n",
    "            random_state=0\n",
    "        )\n",
    "        model_i.fit(X_rest, y_rest)\n",
    "        y_pred = model_i.predict(X_test)\n",
    "\n",
    "        risk_Si = imperical_risk(y_pred, y_test)\n",
    "        #print(f\"Recall: {recall_score(y_test, y_pred)}\")\n",
    "        #print(f\"Precision: {precision_score(y_test, y_pred)}\")\n",
    "        risk += risk_Si\n",
    "        if min_risk_Si > risk_Si:\n",
    "            min_risk_Si = risk_Si\n",
    "            params_star = params_star_i\n",
    "\n",
    "    risk = risk / len(test_split)\n",
    "\n",
    "    X = z_score_normalize(X, indices)\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=params_star['n_estimators'],\n",
    "        max_depth=params_star['max_depth'], \n",
    "        min_samples_split=params_star['min_samples_split'], \n",
    "        min_samples_leaf=params_star['min_samples_leaf'],\n",
    "        class_weight='balanced',\n",
    "        random_state=0\n",
    "    )\n",
    "    print(risk)\n",
    "    print(params_star)\n",
    "\n",
    "#random_forest_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6559999999999999\n",
      "{'C': 0.1, 'degree': 2}\n"
     ]
    }
   ],
   "source": [
    "def svm_poly_classifier():\n",
    "    splits = 5\n",
    "    kf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=0)\n",
    "\n",
    "    X = df[[i for i in df.columns.tolist() if i != 'Creditworthy']].values\n",
    "    y = df['Creditworthy'].values\n",
    "\n",
    "    params = {\n",
    "        'C': [0.1, 1, 10, 100, 1000],\n",
    "        'degree': [2, 3, 4, 5, 7, 9, 10],\n",
    "    }\n",
    "\n",
    "    test_split = [v for v in kf.split(X, y)]\n",
    "\n",
    "    params_star = {\n",
    "        'C': 0.1,\n",
    "        'degree': 2\n",
    "    }\n",
    "\n",
    "    risk = 0\n",
    "    min_risk_Si = np.inf\n",
    "\n",
    "    for i, (rest_index, test_index) in enumerate(test_split):\n",
    "        X_test = X[test_index]\n",
    "        X_test = z_score_normalize(X_test, indices)\n",
    "        y_test = y[test_index]\n",
    "\n",
    "        X_rest = X[rest_index]\n",
    "        y_rest = y[rest_index]\n",
    "\n",
    "        tune_split = [v for v in kf.split(X_rest, y_rest)]\n",
    "        min_risk_without_Si = np.inf\n",
    "        params_star_i = {\n",
    "            'C': 0.1,\n",
    "            'degree': 2\n",
    "        }\n",
    "\n",
    "        for C in params['C']:\n",
    "            for degree in params['degree']:\n",
    "\n",
    "                risk_without_Si = 0\n",
    "\n",
    "                for j, (train_index, tune_index) in enumerate(tune_split):\n",
    "                    X_train = X[train_index]\n",
    "                    X_train = z_score_normalize(X_train, indices)\n",
    "                    y_train = y[train_index]\n",
    "\n",
    "                    X_tune = X[tune_index]\n",
    "                    X_tune = z_score_normalize(X_tune, indices)\n",
    "                    y_tune = y[tune_index]\n",
    "\n",
    "                    model_ij = svm.SVC(C=C, degree=degree, kernel='poly', random_state=0, class_weight='balanced')\n",
    "                    model_ij.fit(X_train, y_train)\n",
    "\n",
    "                    y_pred = model_ij.predict(X_tune)\n",
    "                    risk_Sj = imperical_risk(y_pred, y_tune)\n",
    "                    risk_without_Si += risk_Sj\n",
    "\n",
    "                risk_without_Si = risk_without_Si / splits\n",
    "\n",
    "                if min_risk_without_Si > risk_without_Si:\n",
    "                    params_star_i = {\n",
    "                        'C': C,\n",
    "                        'degree': degree\n",
    "                    }\n",
    "                    min_risk_without_Si = risk_without_Si\n",
    "            \n",
    "        X_rest = z_score_normalize(X_rest, indices)\n",
    "\n",
    "        model_i = svm.SVC(C=params_star_i['C'], degree=params_star_i['degree'], kernel='poly', random_state=0, class_weight='balanced',)\n",
    "        model_i.fit(X_rest, y_rest)\n",
    "        y_pred = model_i.predict(X_test)\n",
    "\n",
    "        risk_Si = imperical_risk(y_pred, y_test)\n",
    "        #print(f\"Recall: {recall_score(y_test, y_pred)}\")\n",
    "        #print(f\"Precision: {precision_score(y_test, y_pred)}\")\n",
    "        risk += risk_Si\n",
    "        if min_risk_Si > risk_Si:\n",
    "            min_risk_Si = risk_Si\n",
    "            params_star = params_star_i\n",
    "\n",
    "    risk = risk / len(test_split)\n",
    "\n",
    "    X = z_score_normalize(X, indices)\n",
    "    model = svm.SVC(C=params_star['C'], degree=params_star['degree'], kernel='poly', random_state=0, class_weight='balanced',)\n",
    "    print(risk)\n",
    "    print(params_star)\n",
    "\n",
    "svm_poly_classifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "object __array__ method not producing an array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[104], line 105\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28mprint\u001b[39m(risk)\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28mprint\u001b[39m(params_star)\n\u001b[0;32m--> 105\u001b[0m \u001b[43mneural_network_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \n",
      "Cell \u001b[0;32mIn[104], line 64\u001b[0m, in \u001b[0;36mneural_network_classifier\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m model_ij \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[1;32m     57\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m64\u001b[39m,)),\n\u001b[1;32m     58\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDropout(dropout),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     61\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     62\u001b[0m ])\n\u001b[1;32m     63\u001b[0m model_ij\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 64\u001b[0m \u001b[43mmodel_ij\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m decision(\u001b[38;5;241m0.5\u001b[39m, model_ij\u001b[38;5;241m.\u001b[39mpredict(X_tune))\n\u001b[1;32m     67\u001b[0m risk_Sj \u001b[38;5;241m=\u001b[39m imperical_risk(y_pred, y_tune)\n",
      "File \u001b[0;32m~/workspace/Project_4_Creditworthiness/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/workspace/Project_4_Creditworthiness/.venv/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:108\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    106\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    107\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: object __array__ method not producing an array"
     ]
    }
   ],
   "source": [
    "def decision(threshold, y):\n",
    "    for i, v in enumerate(y):\n",
    "        if y < threshold:\n",
    "            y[i] = -1\n",
    "        else:\n",
    "            y[i] = 1\n",
    "    return y\n",
    "\n",
    "def neural_network_classifier():\n",
    "    splits = 5\n",
    "    kf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=0)\n",
    "\n",
    "    X = df[[i for i in df.columns.tolist() if i != 'Creditworthy']].values\n",
    "    y = df['Creditworthy'].values\n",
    "\n",
    "    params = {\n",
    "        'dropout': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "    }\n",
    "\n",
    "    test_split = [v for v in kf.split(X, y)]\n",
    "\n",
    "    params_star = {\n",
    "        'dropout': 0.0,\n",
    "    }\n",
    "\n",
    "    risk = 0\n",
    "    min_risk_Si = np.inf\n",
    "\n",
    "    for i, (rest_index, test_index) in enumerate(test_split):\n",
    "        X_test = X[test_index]\n",
    "        X_test = z_score_normalize(X_test, indices)\n",
    "        y_test = y[test_index]\n",
    "\n",
    "        X_rest = X[rest_index]\n",
    "        y_rest = y[rest_index]\n",
    "\n",
    "        tune_split = [v for v in kf.split(X_rest, y_rest)]\n",
    "        min_risk_without_Si = np.inf\n",
    "        params_star_i = {\n",
    "            'dropout': 0.0,\n",
    "        }\n",
    "\n",
    "        for dropout in params['dropout']:\n",
    "\n",
    "            risk_without_Si = 0\n",
    "\n",
    "            for j, (train_index, tune_index) in enumerate(tune_split):\n",
    "                X_train = X[train_index]\n",
    "                X_train = z_score_normalize(X_train, indices)\n",
    "                y_train = y[train_index]\n",
    "\n",
    "                X_tune = X[tune_index]\n",
    "                X_tune = z_score_normalize(X_tune, indices)\n",
    "                y_tune = y[tune_index]\n",
    "\n",
    "                model_ij = tf.keras.models.Sequential([\n",
    "                    tf.keras.layers.Input(shape=(64,)),\n",
    "                    tf.keras.layers.Dropout(dropout),\n",
    "                    tf.keras.layers.Dense(128, activation='relu'),\n",
    "                    tf.keras.layers.Dropout(dropout),\n",
    "                    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "                ])\n",
    "                model_ij.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_squared_error'])\n",
    "                model_ij.fit(x=X_train, y=y_train, epochs=2000)\n",
    "\n",
    "                y_pred = decision(0.5, model_ij.predict(X_tune))\n",
    "                risk_Sj = imperical_risk(y_pred, y_tune)\n",
    "                risk_without_Si += risk_Sj\n",
    "\n",
    "            risk_without_Si = risk_without_Si / splits\n",
    "\n",
    "            if min_risk_without_Si > risk_without_Si:\n",
    "                params_star_i = {\n",
    "                    'dropout': dropout,\n",
    "                }\n",
    "                min_risk_without_Si = risk_without_Si\n",
    "            \n",
    "        X_rest = z_score_normalize(X_rest, indices)\n",
    "\n",
    "        model_i = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Input(shape=(64,)),\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dropout(dropout),\n",
    "            tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        model_i.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_squared_error'])\n",
    "        model_i.fit(x=X_rest, y=y_rest, epochs=2000)\n",
    "        y_pred = decision(0.5, model_i.predict(X_test))\n",
    "\n",
    "        risk_Si = imperical_risk(y_pred, y_test)\n",
    "        #print(f\"Recall: {recall_score(y_test, y_pred)}\")\n",
    "        #print(f\"Precision: {precision_score(y_test, y_pred)}\")\n",
    "        risk += risk_Si\n",
    "        if min_risk_Si > risk_Si:\n",
    "            min_risk_Si = risk_Si\n",
    "            params_star = params_star_i\n",
    "\n",
    "    risk = risk / len(test_split)\n",
    "\n",
    "    X = z_score_normalize(X, indices)\n",
    "    # TODO model = svm.SVC(C=params_star['C'], degree=params_star['degree'], kernel='poly', random_state=0, class_weight='balanced',)\n",
    "    print(risk)\n",
    "    print(params_star)\n",
    "\n",
    "neural_network_classifier() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# risk = 0\n",
    "\n",
    "# for index, row in df.iterrows():\n",
    "#     rest = df\n",
    "#     rest = rest.drop(index)\n",
    "#     for label in numerical_non_missing:\n",
    "#         rest[label] = z_score(rest[label])   \n",
    "\n",
    "#     X_test = df_norm.loc[index][[i for i in df_norm.columns.tolist() if i != 'Creditworthy']].values.reshape(1,-1)\n",
    "#     y_test = row['Creditworthy'].values\n",
    "\n",
    "#     kf = StratifiedKFold(n_splits=4, shuffle=True, random_state=0)\n",
    "\n",
    "#     X_rest = rest[[i for i in rest.columns.tolist() if i != 'Creditworthy']].values\n",
    "#     y_rest = rest['Creditworthy'].values\n",
    "\n",
    "#     for train_index, tune_index in kf.split(X_rest, y_rest):\n",
    "#         X_train = X_rest[train_index]\n",
    "#         y_train = y_rest[train_index]\n",
    "\n",
    "#         X_tune = X_rest[tune_index]\n",
    "#         y_tune = y_rest[tune_index]\n",
    "\n",
    "#         i = 0.1\n",
    "#         while i <= 100.0:\n",
    "#             clf = svm.SVC(C=i, random_state=0, kernel='rbf')\n",
    "#             clf.fit(X_train, y_train)\n",
    "\n",
    "#             y_pred = clf.predict(X_test)\n",
    "#             i += 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.loc[df['Foreign worker'] == 'A201', 'Foreign worker'] = 1.0\n",
    "# df.loc[df['Foreign worker'] == 'A202', 'Foreign worker'] = 0.0\n",
    "\n",
    "# fw_data = df[df.columns.tolist()[3:]]\n",
    "# fw_data.loc[fw_data['Creditworthy'] == 1, 'Creditworthy'] = 0.0\n",
    "# fw_data.loc[fw_data['Creditworthy'] == 2, 'Creditworthy'] = 1.0\n",
    "\n",
    "# missing = fw_data.loc[fw_data['Foreign worker'] == '?']\n",
    "# fw_data = fw_data.loc[fw_data['Foreign worker'] != '?']\n",
    "# fw_data['Foreign worker'] = fw_data['Foreign worker'].astype('int64')\n",
    "\n",
    "# fw_data_norm = fw_data\n",
    "# for label in numerical_non_missing:\n",
    "#     fw_data_norm[label] = z_score(fw_data_norm[label])\n",
    "\n",
    "# risk = 0\n",
    "\n",
    "# for index, row in fw_data.iterrows():\n",
    "#     rest = fw_data\n",
    "#     rest = rest.drop(index)\n",
    "#     for label in numerical_non_missing:\n",
    "#         rest[label] = z_score(rest[label])\n",
    "\n",
    "#     X_test = fw_data_norm.loc[index][[i for i in fw_data_norm.columns.tolist() if i != 'Foreign worker']].values.reshape(1,-1)\n",
    "#     y_test = row['Foreign worker']\n",
    "\n",
    "#     X_train = rest[[i for i in rest.columns.tolist() if i != 'Foreign worker']]\n",
    "#     y_train = rest['Foreign worker']\n",
    "\n",
    "#     clf = RandomForestClassifier(max_depth=10, n_estimators=1000, random_state=0, criterion='entropy', class_weight='balanced')\n",
    "#     clf.fit(X_train, y_train)\n",
    "\n",
    "#     y_pred = clf.predict(X_test)\n",
    "\n",
    "#     if y_pred != y_test:\n",
    "#         risk += 1\n",
    "\n",
    "# print(risk)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# risk = 0\n",
    "\n",
    "# for index, row in df.iterrows():\n",
    "#     rest = df\n",
    "#     rest = rest.drop(index)\n",
    "#     for label in numerical_non_missing:\n",
    "#         rest[label] = z_score(rest[label])\n",
    "\n",
    "#     X_test = df_norm.loc[index][[i for i in df_norm.columns.tolist() if i != 'Creditworthy']].values.reshape(1,-1)\n",
    "#     y_test = row['Creditworthy']\n",
    "\n",
    "#     X_train = rest[[i for i in rest.columns.tolist() if i != 'Creditworthy']]\n",
    "#     y_train = rest['Creditworthy']\n",
    "\n",
    "#     clf = RandomForestClassifier(max_depth=5, n_estimators=100, random_state=0, criterion='entropy')\n",
    "#     clf.fit(X_train, y_train)\n",
    "\n",
    "#     y_pred = clf.predict(X_test)\n",
    "\n",
    "#     if y_pred != y_test:\n",
    "#         risk += 1\n",
    "\n",
    "# print(risk)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
